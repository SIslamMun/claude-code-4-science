---
description: Optimize HDF5 file structure for better I/O performance
argument-hint: <file-path> [chunk-size]
allowed-tools: Task, Read, Write, Bash
---

## ðŸš€ HDF5 Optimization

Target file: $ARGUMENTS

I'll delegate this to the data-expert who has exclusive access to HDF5 MCP tools for optimization.

### Optimization Process
1. **Analysis** - Profile current HDF5 structure using mcp__hdf5__info
2. **Chunking** - Calculate optimal chunk sizes based on access patterns
3. **Compression** - Select best compression algorithm (GZIP, SZIP, BLOSC)
4. **Restructure** - Apply optimizations using mcp__hdf5__write
5. **Validation** - Benchmark before/after performance

The data-expert will provide:
- Original vs optimized file sizes
- Read/write performance metrics (MB/s)
- Compression ratios achieved
- Recommended further optimizations

Delegating to data-expert with HDF5 MCPs...